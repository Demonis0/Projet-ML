To make the project running:

- Start Ollama
- Launch the "Launch.bat" script: it will start the diffusion stable model's server, the flask API and front servers.
